{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c040696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed54807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52515fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []\n",
    "label = []\n",
    "# 建立类别标签，不同类别对应不同的数字。\n",
    "label_dict = {'aloe': 0, 'burger': 1, 'cabbage': 2,'candied_fruits':3, 'carrots': 4, 'chips':5,\n",
    "                  'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream':11,\n",
    "                  'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon':17,\n",
    "                  'soup': 18, 'wings': 19}\n",
    "label_dict_inv = {v:k for k,v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699fc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_features(parent_dir, sub_dirs, max_file=10, file_ext=\"*.wav\"):\n",
    "    label, feature = [], []\n",
    "    for sub_dir in sub_dirs:\n",
    "        for fn in tqdm(glob.glob(os.path.join(parent_dir, sub_dir, file_ext))[:max_file]):\n",
    "            # 加载原始音频（不添加噪声）\n",
    "            X, sample_rate = librosa.load(fn, res_type='kaiser_fast')\n",
    "            \n",
    "            # 提取梅尔频谱\n",
    "            mels = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128)\n",
    "            mels_db = librosa.power_to_db(mels)\n",
    "            mels_mean = np.mean(mels_db.T, axis=0)\n",
    "            \n",
    "            # 提取MFCC\n",
    "            mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "            mfccs_delta = librosa.feature.delta(mfccs)\n",
    "            mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "            mfccs_combined = np.concatenate([mfccs, mfccs_delta, mfccs_delta2], axis=0)\n",
    "            mfccs_mean = np.mean(mfccs_combined.T, axis=0)\n",
    "            \n",
    "            # 特征融合\n",
    "            combined_feature = np.concatenate([mels_mean, mfccs_mean])\n",
    "            feature.append(combined_feature)\n",
    "            label.append(label_dict[sub_dir])\n",
    "    \n",
    "    return [feature, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f331ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [00:07<00:00, 44.95it/s]\n",
      "100%|██████████| 340/340 [00:07<00:00, 44.95it/s]\n",
      "100%|██████████| 372/372 [00:08<00:00, 44.23it/s]\n",
      "100%|██████████| 372/372 [00:08<00:00, 44.23it/s]\n",
      "100%|██████████| 329/329 [00:14<00:00, 22.38it/s]\n",
      "100%|██████████| 329/329 [00:14<00:00, 22.38it/s]\n",
      "100%|██████████| 499/499 [00:20<00:00, 24.25it/s]\n",
      "100%|██████████| 499/499 [00:20<00:00, 24.25it/s]\n",
      "100%|██████████| 413/413 [00:14<00:00, 28.09it/s]\n",
      "100%|██████████| 413/413 [00:14<00:00, 28.09it/s]\n",
      "100%|██████████| 446/446 [00:16<00:00, 27.37it/s]\n",
      "100%|██████████| 446/446 [00:16<00:00, 27.37it/s]\n",
      "100%|██████████| 178/178 [00:06<00:00, 27.94it/s]\n",
      "100%|██████████| 178/178 [00:06<00:00, 27.94it/s]\n",
      "100%|██████████| 191/191 [00:05<00:00, 32.92it/s]\n",
      "100%|██████████| 191/191 [00:05<00:00, 32.92it/s]\n",
      "100%|██████████| 405/405 [00:13<00:00, 30.28it/s]\n",
      "100%|██████████| 405/405 [00:13<00:00, 30.28it/s]\n",
      "100%|██████████| 345/345 [00:12<00:00, 28.09it/s]\n",
      "100%|██████████| 345/345 [00:12<00:00, 28.09it/s]\n",
      "100%|██████████| 446/446 [00:16<00:00, 27.04it/s]\n",
      "100%|██████████| 446/446 [00:16<00:00, 27.04it/s]\n",
      "100%|██████████| 458/458 [00:17<00:00, 25.71it/s]\n",
      "100%|██████████| 458/458 [00:17<00:00, 25.71it/s]\n",
      "100%|██████████| 289/289 [00:10<00:00, 28.14it/s]\n",
      "100%|██████████| 289/289 [00:10<00:00, 28.14it/s]\n",
      "100%|██████████| 251/251 [00:08<00:00, 31.12it/s]\n",
      "100%|██████████| 251/251 [00:08<00:00, 31.12it/s]\n",
      "100%|██████████| 538/538 [00:20<00:00, 26.78it/s]\n",
      "100%|██████████| 538/538 [00:20<00:00, 26.78it/s]\n",
      "100%|██████████| 400/400 [00:16<00:00, 24.70it/s]\n",
      "100%|██████████| 400/400 [00:16<00:00, 24.70it/s]\n",
      "100%|██████████| 311/311 [00:11<00:00, 27.18it/s]\n",
      "100%|██████████| 311/311 [00:11<00:00, 27.18it/s]\n",
      "100%|██████████| 306/306 [00:12<00:00, 24.98it/s]\n",
      "100%|██████████| 306/306 [00:12<00:00, 24.98it/s]\n",
      "100%|██████████| 185/185 [00:04<00:00, 39.90it/s]\n",
      "100%|██████████| 185/185 [00:04<00:00, 39.90it/s]\n",
      "100%|██████████| 298/298 [00:10<00:00, 27.49it/s]\n",
      "100%|██████████| 298/298 [00:10<00:00, 27.49it/s]\n"
     ]
    }
   ],
   "source": [
    "parent_dir = './train/'\n",
    "save_dir = \"./\"\n",
    "folds = sub_dirs = np.array(['aloe','burger','cabbage','candied_fruits',\n",
    "                             'carrots','chips','chocolate','drinks','fries',\n",
    "                            'grapes','gummies','ice-cream','jelly','noodles','pickles',\n",
    "                            'pizza','ribs','salmon','soup','wings'])\n",
    "\n",
    "X, Y = extract_features(parent_dir, sub_dirs, max_file=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d51219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (4900, 248)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1, stratify=Y)\n",
    "\n",
    "# 转换为NumPy数组\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)  # (4900, 248)\n",
    "\n",
    "# 补零到256维，再reshape为(N, 1, 16, 16)\n",
    "pad_width = 256 - X_train.shape[1]\n",
    "X_train = np.pad(X_train, ((0,0),(0,pad_width)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(0,pad_width)), 'constant')\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 16, 16)\n",
    "X_test = X_test.reshape(-1, 1, 16, 16)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(Y_train))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15156c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a95ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super().__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.residual = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.residual(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.dropout(out)\n",
    "        out += identity\n",
    "        return self.relu(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfa547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAudioClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(32, 64, downsample=True),\n",
    "            BasicBlock(64, 64)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, downsample=True),\n",
    "            BasicBlock(128, 128)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, downsample=True),\n",
    "            BasicBlock(256, 256)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d0a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        log_prob = F.log_softmax(pred, dim=-1)\n",
    "        nll_loss = -log_prob.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -log_prob.mean(dim=-1)\n",
    "        loss = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3757c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = AudioClassifier().to(device)\n",
    "model = ResNetAudioClassifier().to(device)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,          # 默认学习率\n",
    "    weight_decay=0.01  # L2正则化系数λ（建议初始值范围[1e-5, 1e-3]）\n",
    ")\n",
    "\n",
    "criterion = LabelSmoothingLoss(smoothing=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ac775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, \n",
    "                num_epochs=100, validate_every=10, show_progress_every=1):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    - validate_every: 每多少轮验证一次\n",
    "    - show_progress_every: 每多少轮显示一次进度条\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # 控制进度条显示频率\n",
    "        loader = train_loader if (epoch+1) % show_progress_every == 0 else train_loader\n",
    "        disable_progress = not ((epoch+1) % show_progress_every == 0)\n",
    "        \n",
    "        for inputs, labels in tqdm(loader, \n",
    "                                 desc=f\"Epoch {epoch+1}/{num_epochs}\", \n",
    "                                 unit=\"batch\",\n",
    "                                 disable=disable_progress):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # 验证阶段（根据设置频率）\n",
    "        if (epoch + 1) % validate_every == 0 or epoch == num_epochs - 1:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_loss = val_loss / len(test_loader)\n",
    "            val_acc = 100 * val_correct / val_total\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "            print(\"-\" * 50)\n",
    "        else:\n",
    "            # 非验证epoch只显示简单信息\n",
    "            if not disable_progress:\n",
    "                print(f\"\\nEpoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.2f}%\")\n",
    "        \n",
    "        # 每个epoch后更新学习率\n",
    "        scheduler.step()\n",
    "    \n",
    "    # 训练完成后打印最终结果\n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Final Train Accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    # 确保最后一个epoch验证过\n",
    "    if (num_epochs - 1) % validate_every != 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb5e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/500: 100%|██████████| 77/77 [00:00<00:00, 232.03batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/500\n",
      "Train Loss: 0.6317 | Train Acc: 99.69%\n",
      "Val Loss: 0.7166 | Val Acc: 95.86%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: 100%|██████████| 77/77 [00:00<00:00, 233.46batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/500\n",
      "Train Loss: 0.6011 | Train Acc: 100.00%\n",
      "Val Loss: 0.6852 | Val Acc: 96.67%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/500: 100%|██████████| 77/77 [00:00<00:00, 232.38batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150/500\n",
      "Train Loss: 0.6194 | Train Acc: 99.71%\n",
      "Val Loss: 0.6977 | Val Acc: 96.19%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: 100%|██████████| 77/77 [00:00<00:00, 228.38batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/500\n",
      "Train Loss: 0.6148 | Train Acc: 99.88%\n",
      "Val Loss: 0.6925 | Val Acc: 96.62%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250/500: 100%|██████████| 77/77 [00:00<00:00, 231.92batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 250/500\n",
      "Train Loss: 0.6039 | Train Acc: 100.00%\n",
      "Val Loss: 0.6633 | Val Acc: 97.90%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: 100%|██████████| 77/77 [00:00<00:00, 222.15batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 300/500\n",
      "Train Loss: 0.6009 | Train Acc: 100.00%\n",
      "Val Loss: 0.6540 | Val Acc: 98.14%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 350/500: 100%|██████████| 77/77 [00:00<00:00, 230.27batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 350/500\n",
      "Train Loss: 0.6039 | Train Acc: 100.00%\n",
      "Val Loss: 0.6602 | Val Acc: 98.10%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: 100%|██████████| 77/77 [00:00<00:00, 234.60batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 400/500\n",
      "Train Loss: 0.6136 | Train Acc: 99.80%\n",
      "Val Loss: 0.6828 | Val Acc: 96.90%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 450/500: 100%|██████████| 77/77 [00:00<00:00, 234.70batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 450/500\n",
      "Train Loss: 0.6034 | Train Acc: 100.00%\n",
      "Val Loss: 0.6615 | Val Acc: 97.76%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████| 77/77 [00:00<00:00, 232.79batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 500/500\n",
      "Train Loss: 0.6016 | Train Acc: 100.00%\n",
      "Val Loss: 0.6497 | Val Acc: 98.43%\n",
      "--------------------------------------------------\n",
      "\n",
      "Training completed!\n",
      "Final Train Accuracy: 100.00%\n",
      "Final Validation Accuracy: 98.43%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, test_loader, criterion, optimizer, \n",
    "           num_epochs=500, validate_every=50, show_progress_every=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a7a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_features(test_dir, max_file=None, file_ext=\"*.wav\"):\n",
    "    features = []\n",
    "    file_list = glob.glob(os.path.join(test_dir, file_ext))\n",
    "    if max_file is not None:\n",
    "        file_list = file_list[:max_file]\n",
    "    \n",
    "    for fn in tqdm(file_list):\n",
    "        # 加载音频（不添加噪声）\n",
    "        X, sample_rate = librosa.load(fn, res_type='kaiser_fast')\n",
    "        \n",
    "        # 梅尔频谱提取（与训练集参数一致）\n",
    "        mels = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128)\n",
    "        mels_db = librosa.power_to_db(mels)\n",
    "        mels_mean = np.mean(mels_db.T, axis=0)\n",
    "        \n",
    "        # MFCC及差分特征提取（与训练集逻辑相同）\n",
    "        mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_delta = librosa.feature.delta(mfccs)\n",
    "        mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        mfccs_combined = np.concatenate([mfccs, mfccs_delta, mfccs_delta2], axis=0)\n",
    "        mfccs_mean = np.mean(mfccs_combined.T, axis=0)\n",
    "        \n",
    "        # 特征融合（保持128+120维）\n",
    "        combined_feature = np.concatenate([mels_mean, mfccs_mean])\n",
    "        # 补零到256维\n",
    "        pad_width = 256 - combined_feature.shape[0]\n",
    "        combined_feature = np.pad(combined_feature, (0, pad_width), 'constant')\n",
    "        features.append(combined_feature)\n",
    "    \n",
    "    return torch.FloatTensor(np.array(features)), file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e056126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:12<00:00, 27.41it/s]\n",
      "100%|██████████| 2000/2000 [01:12<00:00, 27.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features, file_list = extract_test_features('./test_a/')\n",
    "test_features = test_features.view(-1, 1, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324b0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # 返回类别名称而不是数字\n",
    "        return [label_dict_inv[int(i)] for i in predicted.cpu().numpy()]\n",
    "predictions = predict(model, test_features)\n",
    "preds = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "692edf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用file_list保证name和label顺序一致\n",
    "result = pd.DataFrame({'name': [os.path.basename(x) for x in file_list], 'label': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b972bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['name'] = result['name'].apply(lambda x: x.split('/')[-1])\n",
    "result.to_csv('submit.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed731139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001 submit.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./test_a/*.wav | wc -l\n",
    "!wc -l submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a9564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2138606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "067c7e3b",
   "metadata": {},
   "source": [
    "# 训练集验证分数高但测试集分数低的常见原因与排查建议\n",
    "\n",
    "1. **数据分布不一致**  \n",
    "   - 检查训练/验证集与测试集的分布是否一致，类别比例是否均衡。\n",
    "   - 检查是否存在数据泄漏或采样方式不当。\n",
    "\n",
    "2. **特征处理不一致**  \n",
    "   - 确认训练/验证集与测试集的特征提取、padding、reshape等所有预处理步骤完全一致。\n",
    "   - 包括梅尔频谱、MFCC、补零、reshape等。\n",
    "\n",
    "3. **标签映射问题**  \n",
    "   - 检查label_dict和label_dict_inv的使用，确保预测输出与提交label一致。\n",
    "   - 确认predict函数输出为类别名称且顺序正确。\n",
    "\n",
    "4. **模型过拟合**  \n",
    "   - 如果模型在训练/验证集表现很好但测试集很差，可能过拟合。\n",
    "   - 可尝试增加正则化、数据增强、减少模型复杂度等。\n",
    "\n",
    "5. **提交文件格式问题**  \n",
    "   - 检查提交的csv文件格式，name和label列是否与官方要求一致。\n",
    "   - name列应为音频文件名（不含路径），label列为类别名称。\n",
    "\n",
    "6. **建议排查步骤**  \n",
    "   - 随机抽查部分测试集样本，手动对比特征与训练集一致性。\n",
    "   - 检查predict函数和label映射逻辑。\n",
    "   - 检查csv文件内容与格式。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
