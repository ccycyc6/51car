{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-10 19:15:05--  http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/train_sample.zip\n",
      "Resolving tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)... 183.131.227.248\n",
      "Connecting to tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)|183.131.227.248|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 540689175 (516M) [application/zip]\n",
      "Saving to: ‘train_sample.zip’\n",
      "\n",
      "train_sample.zip    100%[===================>] 515.64M  3.43MB/s    in 1m 47s  \n",
      "\n",
      "2025-05-10 19:16:53 (4.81 MB/s) - ‘train_sample.zip’ saved [540689175/540689175]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/train_sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq train_sample.zip\n",
    "!\\rm train_sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d956e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-10 19:19:06--  http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/test_a.zip\n",
      "Resolving tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)... 183.131.227.248\n",
      "Connecting to tianchi-competition.oss-cn-hangzhou.aliyuncs.com (tianchi-competition.oss-cn-hangzhou.aliyuncs.com)|183.131.227.248|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1092637852 (1.0G) [application/zip]\n",
      "Saving to: ‘test_a.zip’\n",
      "\n",
      "test_a.zip          100%[===================>]   1.02G  5.46MB/s    in 4m 8s   \n",
      "\n",
      "2025-05-10 19:23:15 (4.20 MB/s) - ‘test_a.zip’ saved [1092637852/1092637852]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531887/test_a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq test_a.zip\n",
    "!\\rm test_a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://mirrors.aliyun.com/pypi/simple pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04729356-175f-4fb2-9986-d553fcb544bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://mirrors.aliyun.com/pypi/simple scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27533bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: resampy in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from resampy) (1.26.0)\n",
      "Requirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.10/site-packages (from resampy) (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.53->resampy) (0.44.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://mirrors.aliyun.com/pypi/simple resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f8d3e-e4c6-4fb5-a1ca-2ebd7973668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.7.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (23.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.7.22)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: resampy in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from resampy) (1.26.0)\n",
      "Requirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.10/site-packages (from resampy) (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.53->resampy) (0.44.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install librosa -i https://pypi.tuna.tsinghua.edu.cn/simple --default-timeout=100\n",
    "!pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afa5d51-2c6f-4161-a61f-1bf515372668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要的PyTorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4b4fa2-e418-4ef8-b4b3-ab20b9adaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db8509-f430-4fed-86f7-4697f4999e12",
   "metadata": {},
   "source": [
    "# 特征提取以及数据集的建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b6e41b-13d6-40ec-badf-6c18832e3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 初始化特征和标签列表\n",
    "feature = []\n",
    "label = []\n",
    "\n",
    "# 建立类别标签，不同类别对应不同的数字\n",
    "label_dict = {'aloe': 0, 'burger': 1, 'cabbage': 2, 'candied_fruits': 3, 'carrots': 4, 'chips': 5,\n",
    "              'chocolate': 6, 'drinks': 7, 'fries': 8, 'grapes': 9, 'gummies': 10, 'ice-cream': 11,\n",
    "              'jelly': 12, 'noodles': 13, 'pickles': 14, 'pizza': 15, 'ribs': 16, 'salmon': 17,\n",
    "              'soup': 18, 'wings': 19}\n",
    "\n",
    "# 创建一个反向字典，用于从数字映射回类别名称\n",
    "label_dict_inv = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# 定义特征提取函数\n",
    "def extract_features_with_noise(parent_dir, sub_dirs, max_file=10, file_ext=\"*.wav\", noise_factor=0.005):\n",
    "    \"\"\"\n",
    "    从音频文件中提取特征和标签，并添加随机噪声进行数据增强。\n",
    "\n",
    "    参数:\n",
    "    - parent_dir: 数据集的父目录\n",
    "    - sub_dirs: 子目录列表，每个子目录对应一个类别\n",
    "    - max_file: 每个类别最多处理的文件数量\n",
    "    - file_ext: 文件扩展名，默认为 \"*.wav\"\n",
    "    - noise_factor: 随机噪声的强度因子\n",
    "\n",
    "    返回:\n",
    "    - feature: 提取的特征列表（包含倒谱MFCC特征）\n",
    "    - label: 对应的标签列表\n",
    "    \"\"\"\n",
    "    label, feature = [], []  # 初始化标签和特征列表\n",
    "\n",
    "    # 遍历每个子目录\n",
    "    for sub_dir in sub_dirs:\n",
    "        for fn in tqdm(glob.glob(os.path.join(parent_dir, sub_dir, file_ext))[:max_file]):\n",
    "            label_name = fn.split('/')[-2]\n",
    "            label.extend([label_dict[label_name]])\n",
    "            \n",
    "            # 加载音频文件\n",
    "            X, sample_rate = librosa.load(fn, res_type='kaiser_fast')\n",
    "            \n",
    "            # 添加随机噪声\n",
    "            noise = np.random.randn(len(X))\n",
    "            X = X + noise_factor * noise\n",
    "            X = np.clip(X, -1.0, 1.0)  # 确保音频数据在 [-1, 1] 范围内\n",
    "            \n",
    "            # 提取倒谱MFCC特征\n",
    "            mfcc_features = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            \n",
    "            # 添加到特征列表\n",
    "            feature.extend([mfcc_features])\n",
    "    \n",
    "    return [feature, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b60718-3c06-423e-97a6-c42144f03701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 51.27it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 51.27it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 47.43it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 47.43it/s]\n",
      "100%|██████████| 48/48 [00:01<00:00, 26.54it/s]\n",
      "100%|██████████| 48/48 [00:01<00:00, 26.54it/s]\n",
      "100%|██████████| 74/74 [00:02<00:00, 26.42it/s]\n",
      "100%|██████████| 74/74 [00:02<00:00, 26.42it/s]\n",
      "100%|██████████| 49/49 [00:01<00:00, 30.85it/s]\n",
      "100%|██████████| 49/49 [00:01<00:00, 30.85it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 31.21it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 31.21it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 33.67it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 33.67it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 36.41it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 36.41it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 35.73it/s]\n",
      "100%|██████████| 57/57 [00:01<00:00, 35.73it/s]\n",
      "100%|██████████| 61/61 [00:01<00:00, 31.07it/s]\n",
      "100%|██████████| 61/61 [00:01<00:00, 31.07it/s]\n",
      "100%|██████████| 65/65 [00:02<00:00, 30.34it/s]\n",
      "100%|██████████| 65/65 [00:02<00:00, 30.34it/s]\n",
      "100%|██████████| 69/69 [00:02<00:00, 28.91it/s]\n",
      "100%|██████████| 69/69 [00:02<00:00, 28.91it/s]\n",
      "100%|██████████| 43/43 [00:01<00:00, 31.59it/s]\n",
      "100%|██████████| 43/43 [00:01<00:00, 31.59it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 31.41it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 31.41it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 28.07it/s]\n",
      "100%|██████████| 75/75 [00:02<00:00, 28.07it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 27.55it/s]\n",
      "100%|██████████| 55/55 [00:01<00:00, 27.55it/s]\n",
      "100%|██████████| 47/47 [00:01<00:00, 30.09it/s]\n",
      "100%|██████████| 47/47 [00:01<00:00, 30.09it/s]\n",
      "100%|██████████| 37/37 [00:01<00:00, 26.25it/s]\n",
      "100%|██████████| 37/37 [00:01<00:00, 26.25it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 46.88it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 46.88it/s]\n",
      "100%|██████████| 35/35 [00:01<00:00, 29.41it/s]\n",
      "100%|██████████| 35/35 [00:01<00:00, 29.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 加载训练数据\n",
    "# 定义训练数据的父目录\n",
    "parent_dir = './train_sample/'\n",
    "\n",
    "# 定义保存目录（当前未使用）\n",
    "save_dir = \"./\"\n",
    "\n",
    "# 定义类别名称数组，每个类别对应一个子目录\n",
    "folds = sub_dirs = np.array(['aloe', 'burger', 'cabbage', 'candied_fruits',\n",
    "                             'carrots', 'chips', 'chocolate', 'drinks', 'fries',\n",
    "                             'grapes', 'gummies', 'ice-cream', 'jelly', 'noodles', 'pickles',\n",
    "                             'pizza', 'ribs', 'salmon', 'soup', 'wings'])\n",
    "\n",
    "# 调用新的特征提取函数，从音频文件中提取倒谱MFCC特征和标签\n",
    "X, Y = extract_features_with_noise(parent_dir, sub_dirs, max_file=100, noise_factor=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872bee5d-8453-4dc6-bdb3-1e93581a57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据分割，将数据集划分为训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n",
    "\n",
    "# 转换为NumPy数组，确保数据格式一致\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# 确保特征数据大小适配模型输入\n",
    "# 计算每个样本的总特征数，并调整形状为 (N, 1, 高度, 宽度)\n",
    "feature_size = X_train.shape[1]  # 获取特征维度\n",
    "height, width = 40, feature_size // 40  # 假设倒谱MFCC特征的高度为40，宽度自动计算\n",
    "if feature_size % 40 != 0:\n",
    "    raise ValueError(f\"特征维度 {feature_size} 无法整除高度 {height}，请检查特征提取逻辑。\")\n",
    "\n",
    "# 调整数据形状\n",
    "X_train = X_train.reshape(-1, 1, height, width)\n",
    "X_test = X_test.reshape(-1, 1, height, width)\n",
    "\n",
    "# 转换为PyTorch张量，创建训练集和测试集的数据集对象\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(Y_train))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74bc3a3f-e142-464b-91c2-3c6220965378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "# 定义批量大小\n",
    "batch_size = 64\n",
    "\n",
    "# 创建训练数据加载器，支持随机打乱数据\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 创建测试数据加载器，不打乱数据\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37ceb88-8887-4a14-935a-d25b78036e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义音频分类器模型（ResNet）\n",
    "class ResNetAudioClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d3bef8-abc8-4553-8196-e63558894984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 实例化 ResNet 模型\n",
    "model = ResNetAudioClassifier(num_classes=20).to(device)\n",
    "\n",
    "# 定义优化器，这里使用Adam优化器，自动调整学习率\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 定义损失函数，这里使用交叉熵损失函数，适用于多分类任务\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2940de13-02f6-4ede-bc8b-00c091f65f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetAudioClassifier(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 打印模型结构\n",
    "# 通过打印模型，可以查看模型的各层结构和参数信息\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df8544bd-9d06-4bdd-aaaa-79f0b8e311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, \n",
    "                num_epochs=100, validate_every=10, show_progress_every=1):\n",
    "    \"\"\"\n",
    "    训练模型并定期进行验证。\n",
    "\n",
    "    参数:\n",
    "    - model: 要训练的PyTorch模型。\n",
    "    - train_loader: 训练数据集的DataLoader。\n",
    "    - test_loader: 验证数据集的DataLoader。\n",
    "    - criterion: 损失函数，用于计算模型预测与真实标签之间的误差。\n",
    "    - optimizer: 优化算法，用于更新模型参数。\n",
    "    - num_epochs: 训练的总轮数（默认值: 100）。\n",
    "    - validate_every: 每隔多少轮进行一次验证（默认值: 10）。\n",
    "    - show_progress_every: 每隔多少轮显示一次进度条（默认值: 1）。\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        # 设置模型为训练模式，启用dropout和batch normalization等训练特性\n",
    "        model.train()\n",
    "        \n",
    "        # 初始化训练损失、正确预测计数和样本总数\n",
    "        train_loss = 0.0  # 累计训练损失\n",
    "        train_correct = 0  # 累计正确预测的样本数\n",
    "        train_total = 0  # 累计训练样本总数\n",
    "\n",
    "        # 控制是否显示进度条\n",
    "        loader = train_loader if (epoch+1) % show_progress_every == 0 else train_loader\n",
    "        disable_progress = not ((epoch+1) % show_progress_every == 0)\n",
    "\n",
    "        # 遍历训练数据集的每个批次\n",
    "        for inputs, labels in tqdm(loader, \n",
    "                                 desc=f\"Epoch {epoch+1}/{num_epochs}\", \n",
    "                                 unit=\"batch\",\n",
    "                                 disable=disable_progress):\n",
    "            # 将输入和标签移动到设备（CPU/GPU）\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 清零优化器的梯度，避免梯度累积\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播计算输出\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 计算损失，衡量预测与真实标签的差距\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 反向传播计算梯度\n",
    "            loss.backward()\n",
    "            \n",
    "            # 使用优化器更新模型参数\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 累计训练损失\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # 获取预测结果并统计正确预测的数量\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 获取每个样本的预测类别\n",
    "            train_total += labels.size(0)  # 累计样本总数\n",
    "            train_correct += (predicted == labels).sum().item()  # 累计正确预测的样本数\n",
    "        \n",
    "        # 计算平均训练损失和准确率\n",
    "        train_loss = train_loss / len(train_loader)  # 平均训练损失\n",
    "        train_acc = 100 * train_correct / train_total  # 训练准确率（百分比）\n",
    "        \n",
    "        # 验证阶段（根据指定频率）\n",
    "        if (epoch + 1) % validate_every == 0 or epoch == num_epochs - 1:\n",
    "            # 设置模型为评估模式，禁用dropout等训练特性\n",
    "            model.eval()\n",
    "            \n",
    "            # 初始化验证损失、正确预测计数和样本总数\n",
    "            val_loss = 0.0  # 累计验证损失\n",
    "            val_correct = 0  # 累计正确预测的样本数\n",
    "            val_total = 0  # 累计验证样本总数\n",
    "            \n",
    "            # 禁用梯度计算以加速验证过程\n",
    "            with torch.no_grad():\n",
    "                # 遍历验证数据集的每个批次\n",
    "                for inputs, labels in test_loader:\n",
    "                    # 将输入和标签移动到设备（CPU/GPU）\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    \n",
    "                    # 前向传播计算输出\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    # 计算损失\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # 获取预测结果并统计正确预测的数量\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)  # 累计样本总数\n",
    "                    val_correct += (predicted == labels).sum().item()  # 累计正确预测的样本数\n",
    "            \n",
    "            # 计算验证准确率\n",
    "            val_acc = 100 * val_correct / val_total  # 验证准确率（百分比）\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "        else:\n",
    "            # 非验证轮次仅显示训练准确率\n",
    "            if not disable_progress:\n",
    "                print(f\"\\nEpoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.2f}%\")\n",
    "    \n",
    "    # 训练完成后打印最终结果\n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Final Train Accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    # 确保最后一个轮次进行验证（如果未在最后一轮验证）\n",
    "    # 如果最后一个轮次未进行验证，则在训练结束后进行一次最终验证\n",
    "    if (num_epochs - 1) % validate_every != 0:\n",
    "        # 设置模型为评估模式，禁用dropout等训练特性\n",
    "        model.eval()\n",
    "        \n",
    "        # 初始化验证损失、正确预测计数和样本总数\n",
    "        val_loss = 0.0  # 累计验证损失\n",
    "        val_correct = 0  # 累计正确预测的样本数\n",
    "        val_total = 0  # 累计验证样本总数\n",
    "        \n",
    "        # 禁用梯度计算以加速验证过程\n",
    "        with torch.no_grad():\n",
    "            # 遍历验证数据集的每个批次\n",
    "            for inputs, labels in test_loader:\n",
    "                # 将输入和标签移动到设备（CPU/GPU）\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # 前向传播计算输出\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # 计算损失\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # 获取预测结果并统计正确预测的数量\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)  # 累计样本总数\n",
    "                val_correct += (predicted == labels).sum().item()  # 累计正确预测的样本数\n",
    "        \n",
    "        # 计算最终验证准确率\n",
    "        val_acc = 100 * val_correct / val_total  # 验证准确率（百分比）\n",
    "        print(f\"Final Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b39c3f8c-361b-4a97-8d3d-e607b6c6bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/500: 100%|██████████| 13/13 [00:00<00:00, 324.61batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/500 - Train Acc: 96.62%, Val Acc: 54.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: 100%|██████████| 13/13 [00:00<00:00, 318.70batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/500 - Train Acc: 97.12%, Val Acc: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/500: 100%|██████████| 13/13 [00:00<00:00, 329.70batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150/500 - Train Acc: 100.00%, Val Acc: 71.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: 100%|██████████| 13/13 [00:00<00:00, 332.24batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/500 - Train Acc: 99.75%, Val Acc: 72.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 250/500: 100%|██████████| 13/13 [00:00<00:00, 248.36batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 250/500 - Train Acc: 99.38%, Val Acc: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: 100%|██████████| 13/13 [00:00<00:00, 277.73batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 300/500 - Train Acc: 99.25%, Val Acc: 73.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 350/500: 100%|██████████| 13/13 [00:00<00:00, 290.56batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 350/500 - Train Acc: 99.88%, Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: 100%|██████████| 13/13 [00:00<00:00, 274.25batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 400/500 - Train Acc: 99.62%, Val Acc: 68.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 450/500: 100%|██████████| 13/13 [00:00<00:00, 320.04batch/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 450/500 - Train Acc: 100.00%, Val Acc: 76.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████| 13/13 [00:00<00:00, 325.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 500/500 - Train Acc: 100.00%, Val Acc: 72.00%\n",
      "\n",
      "Training completed!\n",
      "Final Train Accuracy: 100.00%\n",
      "Final Validation Accuracy: 72.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 调用 train_model 函数，开始训练音频分类器模型\n",
    "# 参数说明：\n",
    "# - model: 要训练的模型实例\n",
    "# - train_loader: 训练数据的 DataLoader\n",
    "# - test_loader: 测试数据的 DataLoader，用于验证模型性能\n",
    "# - criterion: 损失函数，用于计算预测误差\n",
    "# - optimizer: 优化器，用于更新模型参数\n",
    "# - num_epochs: 训练的总轮数，这里设置为 500\n",
    "# - validate_every: 每隔 50 个 epoch 进行一次验证\n",
    "# - show_progress_every: 每隔 50 个 epoch 显示一次训练进度\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, \n",
    "           num_epochs=500, validate_every=50, show_progress_every=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50741c4-5595-4edd-9549-f9be398cbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_features(test_dir, max_file=None, file_ext=\"*.wav\"):\n",
    "    \"\"\"\n",
    "    从测试音频文件中提取特征。\n",
    "\n",
    "    参数:\n",
    "    - test_dir: 测试数据的目录路径。\n",
    "    - max_file: 最多处理的文件数量（默认值: None，表示处理所有文件）。\n",
    "    - file_ext: 文件扩展名，默认为 \"*.wav\"。\n",
    "\n",
    "    返回:\n",
    "    - features: 提取的特征，作为 PyTorch FloatTensor。\n",
    "    - file_list: 处理的文件路径列表。\n",
    "    \"\"\"\n",
    "    features = []  # 初始化特征列表\n",
    "    file_list = glob.glob(os.path.join(test_dir, file_ext))  # 获取指定目录下的所有音频文件\n",
    "    if max_file is not None:  # 如果指定了最大文件数量\n",
    "        file_list = file_list[:max_file]  # 截取前 max_file 个文件\n",
    "    \n",
    "    # 遍历文件列表，提取每个文件的特征\n",
    "    for fn in tqdm(file_list):\n",
    "        # 加载音频文件\n",
    "        X, sample_rate = librosa.load(fn, res_type='kaiser_fast')\n",
    "        # 计算梅尔频谱（mel spectrogram），并取其均值作为特征\n",
    "        mels = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "        features.append(mels)  # 将特征添加到特征列表中\n",
    "    \n",
    "    features = np.array(features)  # 转换为 NumPy 数组\n",
    "    # 返回特征和文件列表\n",
    "    return torch.FloatTensor(features), file_list\n",
    "\n",
    "def predict(model, test_features):\n",
    "    \"\"\"\n",
    "    使用模型对测试特征进行预测。\n",
    "\n",
    "    参数:\n",
    "    - model: 训练好的 PyTorch 模型。\n",
    "    - test_features: 测试数据的特征，作为 PyTorch 张量。\n",
    "\n",
    "    返回:\n",
    "    - predictions: 预测的类别名称列表。\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式，禁用 dropout 等训练特性\n",
    "    with torch.no_grad():  # 禁用梯度计算以加速预测过程\n",
    "        test_features = test_features.to(device)  # 将特征移动到设备（CPU/GPU）\n",
    "        outputs = model(test_features)  # 前向传播计算输出\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 获取每个样本的预测类别\n",
    "        # 将预测的类别数字映射回类别名称\n",
    "        return [label_dict_inv[p.item()] for p in predicted]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679f8df7-9f56-4e2c-b90d-04fef0e35597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:13<00:00, 27.35it/s]\n",
      "100%|██████████| 2000/2000 [01:13<00:00, 27.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test_features, file_list = extract_test_features('./test_a/')\n",
    "# 调整测试特征的形状以适配模型输入\n",
    "# 这里将特征调整为 (N, 1, 16, 8) 的形状，其中 N 是样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfd80945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整测试特征的形状为 (N, 1, 16, 8)，其中 N 是样本数量\n",
    "# 1 表示单通道（灰度图像），16 和 8 是特征的高和宽\n",
    "# 这种形状适配卷积神经网络的输入格式\n",
    "test_features = test_features.view(-1, 1, 16, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a9d881-2162-4868-8d4b-0b5cefe035f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练好的模型对测试特征进行预测\n",
    "# 参数:\n",
    "# - model: 训练好的音频分类器模型\n",
    "# - test_features: 提取并调整形状后的测试数据特征\n",
    "# 返回:\n",
    "# - predictions: 测试数据的预测类别名称列表\n",
    "predictions = predict(model, test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53dc4cc-928a-42a2-8435-2ae568b7c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果赋值给变量 preds\n",
    "preds = predictions\n",
    "\n",
    "# 获取测试文件的路径列表\n",
    "path = glob.glob('./test_a/*.wav')\n",
    "\n",
    "# 创建一个 DataFrame，将文件路径和预测标签对应起来\n",
    "result = pd.DataFrame({'name': path, 'label': preds})\n",
    "\n",
    "# 提取文件名（去掉路径部分），并更新到 'name' 列\n",
    "result['name'] = result['name'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "# 将结果保存为 CSV 文件，文件名为 'submit.csv'，不包含索引列\n",
    "result.to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c74e8347-b263-47bb-9670-af8d601c684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# 统计测试数据目录中以 .wav 为扩展名的音频文件数量\n",
    "!ls ./test_a/*.wav | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9c6d3f8-58a9-482d-a11a-baa8ac576de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001 submit.csv\n"
     ]
    }
   ],
   "source": [
    "# 使用 wc -l 命令统计 submit.csv 文件中的行数\n",
    "# 这可以用来检查提交文件中包含的记录数量\n",
    "!wc -l submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb4c8a-4645-4e53-b569-b1cc2160ab86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccy",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
